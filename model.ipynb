{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97lfZfOoCUmu"
      },
      "source": [
        "installing Mealpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7Xxk2AjK-IUE",
        "outputId": "b121ea08-c01c-4f14-8945-7a773a13c168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mealpy\n",
            "  Downloading mealpy-3.0.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (2.0.3)\n",
            "Collecting opfunu>=1.0.0 (from mealpy)\n",
            "  Downloading opfunu-1.0.4-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from opfunu>=1.0.0->mealpy) (2.31.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mealpy) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.0->opfunu>=1.0.0->mealpy) (2024.7.4)\n",
            "Installing collected packages: opfunu, mealpy\n",
            "Successfully installed mealpy-3.0.1 opfunu-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mealpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EksDSoq8CVlt"
      },
      "source": [
        "importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2fSBBB1aGgr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
        "import pywt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Bidirectional, LSTM, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIY3mRGsbeUq"
      },
      "outputs": [],
      "source": [
        "# from tensorsflow.keras.models import load_model\n",
        "# model.save('drive location to be saved and extension is .h5 or hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxrWkSoxCgF5"
      },
      "source": [
        "Connecting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T1a0bopqaI-0",
        "outputId": "e4edaf41-fde6-4328-865e-e6a5593b01e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8GmD6zzCiGl"
      },
      "source": [
        "Preprocessing,Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcgAKS_7aLZF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to read and preprocess images\n",
        "def read_and_preprocess_images(image_path, target_size=(224, 224)):\n",
        "    images = []\n",
        "    for filename in os.listdir(image_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img = cv2.imread(os.path.join(image_path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, target_size)\n",
        "            img = np.stack((img,) * 3, axis=-1)  # Convert grayscale to RGB by stacking\n",
        "            img = preprocess_input(img)  # Preprocess using DenseNet function\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images\n",
        "normal_train_images = read_and_preprocess_images('/content/drive/MyDrive/DATASET/train/normal')\n",
        "tumor_train_images = read_and_preprocess_images('/content/drive/MyDrive/DATASET/train/pancreatic_tumor')\n",
        "normal_test_images = read_and_preprocess_images('/content/drive/MyDrive/DATASET/test/normal')\n",
        "tumor_test_images = read_and_preprocess_images('/content/drive/MyDrive/DATASET/test/pancreatic_tumor')\n",
        "\n",
        "# Data Augmentation\n",
        "train_dataset = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_images = train_dataset.flow(\n",
        "    np.concatenate((normal_train_images, tumor_train_images), axis=0),\n",
        "    np.concatenate((np.zeros(normal_train_images.shape[0]), np.ones(tumor_train_images.shape[0])), axis=0),\n",
        "    batch_size=32)\n",
        "\n",
        "\n",
        "test_images = train_dataset.flow(\n",
        "    np.concatenate((normal_test_images, tumor_test_images), axis=0),\n",
        "    np.concatenate((np.zeros(normal_test_images.shape[0]), np.ones(tumor_test_images.shape[0])), axis=0),\n",
        "    batch_size=32)\n",
        "\n",
        "# Create labels for the test data\n",
        "train_labels =  np.concatenate((np.zeros(normal_train_images.shape[0]), np.ones(tumor_train_images.shape[0])), axis=0)\n",
        "test_labels =  np.concatenate((np.zeros(normal_test_images.shape[0]), np.ones(tumor_test_images.shape[0])), axis=0)\n",
        "# Create TensorFlow datasets for training and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-D3GSBfqDvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d1dbf4-d8b4-43ac-aebc-de4dd513cbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create labels for the training data\n",
        "train_labels_normal = np.zeros(normal_train_images.shape[0])\n",
        "train_labels_tumor = np.ones(tumor_train_images.shape[0])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOYCRWq5Cl71"
      },
      "source": [
        "Feature Extraction Using Densenet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cVjgOD0XaQiT",
        "outputId": "be0a3356-5f4e-4ad1-a4f5-a4c3c0f0b0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "32/32 [==============================] - 22s 602ms/step\n",
            "13/13 [==============================] - 8s 557ms/step\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained DenseNet121 model\n",
        "densenet121 = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in densenet121.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define the feature extraction model\n",
        "feature_extractor = tf.keras.Sequential([\n",
        "    densenet121,\n",
        "    GlobalAveragePooling2D()\n",
        "])\n",
        "\n",
        "# Extract features from the preprocessed and labeled CT images\n",
        "train_features = feature_extractor.predict(train_images)\n",
        "test_features = feature_extractor.predict(test_images)\n",
        "\n",
        "# Flatten the features for input to classifiers\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmY3tmhbCq6w"
      },
      "source": [
        "Tried for cloning HHO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjorX0bEcb6K"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/cahitberkay/Harris-Hawks-Optimization-HHO---Python-Code.git\n",
        "# import sys\n",
        "# sys.path.append('Harris-Hawks-Optimization-HHO---Python-Code')\n",
        "# from HHO import HHO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci7h_ET2Dog9"
      },
      "source": [
        "Creating HHO for Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybpBxBHrgdH0"
      },
      "outputs": [],
      "source": [
        "# Harris Hawks Optimization (HHO) Class\n",
        "class HHO:\n",
        "    def __init__(self, objective_function, search_space, pop_size=20, max_iter=50):\n",
        "        self.obj_func = objective_function\n",
        "        self.search_space = search_space\n",
        "        self.pop_size = pop_size\n",
        "        self.max_iter = max_iter\n",
        "        self.position = np.zeros((self.pop_size, len(self.search_space)))\n",
        "        self.fitness = np.zeros(self.pop_size)\n",
        "        self.best_position = np.zeros(len(self.search_space))\n",
        "        self.best_fitness = float('inf')\n",
        "\n",
        "    def initialize_population(self):\n",
        "        for i in range(self.pop_size):\n",
        "            for j in range(len(self.search_space)):\n",
        "                key = list(self.search_space.keys())[j]\n",
        "                # Ensure values are sampled correctly\n",
        "                self.position[i, j] = random.choice(self.search_space[key])\n",
        "\n",
        "    def update_position(self, t):\n",
        "        r1 = random.random()\n",
        "        r2 = random.random()\n",
        "        for i in range(self.pop_size):\n",
        "            if r1 >= 0.5:  # Exploration phase\n",
        "                X_rand = random.choice(self.position)\n",
        "                self.position[i] = self.best_position + r2 * (X_rand - self.position[i])\n",
        "            else:  # Exploitation phase\n",
        "                m = 2 * (1 - t / self.max_iter)\n",
        "                self.position[i] = (self.best_position - self.position[i]) * np.exp(m * t) + self.best_position\n",
        "\n",
        "            # Ensure valid hyperparameter values\n",
        "            self.position[i, 0] = max(1e-5, min(self.position[i, 0], 1e-3))  # Learning rate\n",
        "            self.position[i, 1] = max(0.1, min(self.position[i, 1], 0.5))    # Dropout rate\n",
        "            self.position[i, 2] = max(128, min(int(self.position[i, 2]), 512))  # Dense units\n",
        "\n",
        "            # Evaluate new positions\n",
        "            self.fitness[i] = self.obj_func(dict(zip(self.search_space.keys(), self.position[i])))\n",
        "            if self.fitness[i] < self.best_fitness:\n",
        "                self.best_fitness = self.fitness[i]\n",
        "                self.best_position = self.position[i]\n",
        "\n",
        "    def optimize(self):\n",
        "        self.initialize_population()\n",
        "        for t in range(self.max_iter):\n",
        "            self.update_position(t)\n",
        "        return self.best_position, self.best_fitness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCm0dQGoDwUx"
      },
      "source": [
        "Hyperparameter Tuning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ZN72xbaqBr",
        "outputId": "c534b2af-16cd-4450-8058-5551e11ccbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 35s 926ms/step - loss: 0.7577 - accuracy: 0.5641 - val_loss: 0.5326 - val_accuracy: 0.8152\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 27s 827ms/step - loss: 0.6309 - accuracy: 0.6703 - val_loss: 0.4993 - val_accuracy: 0.8633\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 26s 812ms/step - loss: 0.5468 - accuracy: 0.7475 - val_loss: 0.4598 - val_accuracy: 0.8481\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 26s 820ms/step - loss: 0.4769 - accuracy: 0.8026 - val_loss: 0.4119 - val_accuracy: 0.8861\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 26s 813ms/step - loss: 0.4116 - accuracy: 0.8567 - val_loss: 0.3730 - val_accuracy: 0.9063\n",
            "13/13 [==============================] - 8s 560ms/step - loss: 0.3859 - accuracy: 0.9038\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 34s 871ms/step - loss: 0.6764 - accuracy: 0.5952 - val_loss: 0.6592 - val_accuracy: 0.5899\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 26s 803ms/step - loss: 0.5430 - accuracy: 0.7415 - val_loss: 0.5823 - val_accuracy: 0.7139\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 26s 826ms/step - loss: 0.4561 - accuracy: 0.8277 - val_loss: 0.5184 - val_accuracy: 0.7797\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 27s 834ms/step - loss: 0.3869 - accuracy: 0.8758 - val_loss: 0.4509 - val_accuracy: 0.8354\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 26s 807ms/step - loss: 0.3422 - accuracy: 0.9028 - val_loss: 0.4211 - val_accuracy: 0.8506\n",
            "13/13 [==============================] - 8s 550ms/step - loss: 0.4240 - accuracy: 0.8658\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 34s 899ms/step - loss: 0.7456 - accuracy: 0.5371 - val_loss: 0.7118 - val_accuracy: 0.5570\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 26s 819ms/step - loss: 0.6549 - accuracy: 0.6232 - val_loss: 0.6687 - val_accuracy: 0.6380\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 26s 797ms/step - loss: 0.5676 - accuracy: 0.7044 - val_loss: 0.5906 - val_accuracy: 0.7013\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 26s 800ms/step - loss: 0.4921 - accuracy: 0.7806 - val_loss: 0.5336 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 25s 791ms/step - loss: 0.4191 - accuracy: 0.8387 - val_loss: 0.4749 - val_accuracy: 0.7975\n",
            "13/13 [==============================] - 7s 503ms/step - loss: 0.4768 - accuracy: 0.8000\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 33s 831ms/step - loss: 0.9056 - accuracy: 0.3998 - val_loss: 0.8087 - val_accuracy: 0.5063\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 25s 774ms/step - loss: 0.7511 - accuracy: 0.4800 - val_loss: 0.7359 - val_accuracy: 0.4810\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 25s 764ms/step - loss: 0.6500 - accuracy: 0.6242 - val_loss: 0.6655 - val_accuracy: 0.5899\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 25s 769ms/step - loss: 0.5589 - accuracy: 0.7345 - val_loss: 0.5946 - val_accuracy: 0.7114\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 24s 753ms/step - loss: 0.4900 - accuracy: 0.8397 - val_loss: 0.5461 - val_accuracy: 0.7949\n",
            "13/13 [==============================] - 7s 527ms/step - loss: 0.5444 - accuracy: 0.7747\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 32s 816ms/step - loss: 0.8210 - accuracy: 0.4319 - val_loss: 0.7744 - val_accuracy: 0.4000\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 26s 797ms/step - loss: 0.6964 - accuracy: 0.5281 - val_loss: 0.6820 - val_accuracy: 0.5139\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 26s 795ms/step - loss: 0.6068 - accuracy: 0.6643 - val_loss: 0.6084 - val_accuracy: 0.6430\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 25s 767ms/step - loss: 0.5260 - accuracy: 0.7735 - val_loss: 0.5444 - val_accuracy: 0.7139\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 25s 774ms/step - loss: 0.4539 - accuracy: 0.8487 - val_loss: 0.4707 - val_accuracy: 0.8127\n",
            "13/13 [==============================] - 8s 562ms/step - loss: 0.4871 - accuracy: 0.8025\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 34s 844ms/step - loss: 0.9538 - accuracy: 0.3627 - val_loss: 0.7901 - val_accuracy: 0.4810\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 25s 793ms/step - loss: 0.7646 - accuracy: 0.4960 - val_loss: 0.6889 - val_accuracy: 0.5316\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 25s 785ms/step - loss: 0.6455 - accuracy: 0.6232 - val_loss: 0.6165 - val_accuracy: 0.6506\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 25s 795ms/step - loss: 0.5316 - accuracy: 0.7595 - val_loss: 0.5468 - val_accuracy: 0.7646\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 24s 749ms/step - loss: 0.4852 - accuracy: 0.7966 - val_loss: 0.4914 - val_accuracy: 0.8127\n",
            "13/13 [==============================] - 7s 523ms/step - loss: 0.5003 - accuracy: 0.8076\n",
            "Best hyperparameters:\n",
            "Learning rate: 1e-05\n",
            "Dropout rate: 0.1\n",
            "Dense units: 128.0\n"
          ]
        }
      ],
      "source": [
        "# Define the search space for hyperparameter tuning\n",
        "search_space = {\n",
        "    'learning_rate': [1e-5, 1e-4, 1e-3],  # Ensure positive values\n",
        "    'dropout_rate': [0.1, 0.3, 0.5],      # Ensure values between 0 and 1\n",
        "    'dense_units': [128, 256, 512]        # Ensure positive integers\n",
        "}\n",
        "\n",
        "# Define the objective function for HHO\n",
        "def objective_function(params):\n",
        "    learning_rate = params['learning_rate']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "    dense_units = int(params['dense_units'])\n",
        "\n",
        "    # Ensure dense_units is a positive integer\n",
        "    if dense_units <= 0:\n",
        "        return 1e9  # Penalize invalid dense_units\n",
        "\n",
        "    # Build the model\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(dense_units, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model and evaluate on the test set\n",
        "    model.fit(train_images, epochs=5, validation_data=test_images)\n",
        "    _, val_acc = model.evaluate(test_images)\n",
        "    return -val_acc  # Minimize the negative validation accuracy\n",
        "\n",
        "# Initialize the HHO optimizer\n",
        "hho = HHO(objective_function, search_space, pop_size=2, max_iter=3)\n",
        "best_params, best_fitness = hho.optimize()\n",
        "\n",
        "# Create a dictionary from the best parameters\n",
        "best_params_dict = dict(zip(search_space.keys(), best_params))\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters:\")\n",
        "print(f\"Learning rate: {best_params_dict['learning_rate']}\")\n",
        "print(f\"Dropout rate: {best_params_dict['dropout_rate']}\")\n",
        "print(f\"Dense units: {best_params_dict['dense_units']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDPF02Y2D1Jy"
      },
      "source": [
        "Creating CNN-BiLSTM model for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tPY5CS6CQy-",
        "outputId": "534771f9-1b9c-45f5-da2e-1327181493c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 1022, 64)          256       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 511, 64)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 509, 128)          24704     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 254, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 252, 256)          98560     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 256)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 256)            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1, 256)            394240    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 698882 (2.67 MB)\n",
            "Trainable params: 698882 (2.67 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/46\n",
            "32/32 [==============================] - 8s 72ms/step - loss: 0.6862 - accuracy: 0.5621 - val_loss: 0.7062 - val_accuracy: 0.4734\n",
            "Epoch 2/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6796 - accuracy: 0.5782 - val_loss: 0.7247 - val_accuracy: 0.4734\n",
            "Epoch 3/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6870 - accuracy: 0.5782 - val_loss: 0.7042 - val_accuracy: 0.4734\n",
            "Epoch 4/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6837 - accuracy: 0.5782 - val_loss: 0.7103 - val_accuracy: 0.4734\n",
            "Epoch 5/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7170 - val_accuracy: 0.4734\n",
            "Epoch 6/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6849 - accuracy: 0.5782 - val_loss: 0.7116 - val_accuracy: 0.4734\n",
            "Epoch 7/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6832 - accuracy: 0.5782 - val_loss: 0.7108 - val_accuracy: 0.4734\n",
            "Epoch 8/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7080 - val_accuracy: 0.4734\n",
            "Epoch 9/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6832 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 10/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6835 - accuracy: 0.5782 - val_loss: 0.7101 - val_accuracy: 0.4734\n",
            "Epoch 11/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6824 - accuracy: 0.5782 - val_loss: 0.7113 - val_accuracy: 0.4734\n",
            "Epoch 12/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6818 - accuracy: 0.5782 - val_loss: 0.7116 - val_accuracy: 0.4734\n",
            "Epoch 13/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6818 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 14/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7113 - val_accuracy: 0.4734\n",
            "Epoch 15/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7164 - val_accuracy: 0.4734\n",
            "Epoch 16/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 17/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7123 - val_accuracy: 0.4734\n",
            "Epoch 18/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.7101 - val_accuracy: 0.4734\n",
            "Epoch 19/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7142 - val_accuracy: 0.4734\n",
            "Epoch 20/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6825 - accuracy: 0.5782 - val_loss: 0.7147 - val_accuracy: 0.4734\n",
            "Epoch 21/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 22/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7132 - val_accuracy: 0.4734\n",
            "Epoch 23/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6808 - accuracy: 0.5782 - val_loss: 0.7142 - val_accuracy: 0.4734\n",
            "Epoch 24/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6819 - accuracy: 0.5782 - val_loss: 0.7115 - val_accuracy: 0.4734\n",
            "Epoch 25/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6822 - accuracy: 0.5782 - val_loss: 0.7138 - val_accuracy: 0.4734\n",
            "Epoch 26/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6837 - accuracy: 0.5782 - val_loss: 0.7111 - val_accuracy: 0.4734\n",
            "Epoch 27/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.7107 - val_accuracy: 0.4734\n",
            "Epoch 28/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7119 - val_accuracy: 0.4734\n",
            "Epoch 29/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6796 - accuracy: 0.5782 - val_loss: 0.7147 - val_accuracy: 0.4734\n",
            "Epoch 30/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6826 - accuracy: 0.5782 - val_loss: 0.7150 - val_accuracy: 0.4734\n",
            "Epoch 31/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6819 - accuracy: 0.5782 - val_loss: 0.7163 - val_accuracy: 0.4734\n",
            "Epoch 32/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7114 - val_accuracy: 0.4734\n",
            "Epoch 33/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6825 - accuracy: 0.5782 - val_loss: 0.7111 - val_accuracy: 0.4734\n",
            "Epoch 34/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6806 - accuracy: 0.5782 - val_loss: 0.7148 - val_accuracy: 0.4734\n",
            "Epoch 35/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6822 - accuracy: 0.5782 - val_loss: 0.7125 - val_accuracy: 0.4734\n",
            "Epoch 36/46\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7148 - val_accuracy: 0.4734\n",
            "Epoch 37/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7144 - val_accuracy: 0.4734\n",
            "Epoch 38/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7132 - val_accuracy: 0.4734\n",
            "Epoch 39/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7135 - val_accuracy: 0.4734\n",
            "Epoch 40/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.7124 - val_accuracy: 0.4734\n",
            "Epoch 41/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7133 - val_accuracy: 0.4734\n",
            "Epoch 42/46\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6822 - accuracy: 0.5782 - val_loss: 0.7137 - val_accuracy: 0.4734\n",
            "Epoch 43/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7113 - val_accuracy: 0.4734\n",
            "Epoch 44/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7132 - val_accuracy: 0.4734\n",
            "Epoch 45/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6801 - accuracy: 0.5782 - val_loss: 0.7113 - val_accuracy: 0.4734\n",
            "Epoch 46/46\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6804 - accuracy: 0.5782 - val_loss: 0.7158 - val_accuracy: 0.4734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5de42ae320>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "\n",
        "def create_cnn_bilstm_model(input_shape, num_classes, lstm_units=128, dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    # CNN part\n",
        "    model.add(Conv1D(64, 3, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Conv1D(128, 3, activation='relu'))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Conv1D(256, 3, activation='relu'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Reshape((1, 256)))\n",
        "    # BiLSTM part\n",
        "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(lstm_units // 2)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Assuming DenseNet has extracted features with shape (number_of_samples, feature_dimension)\n",
        "\n",
        "# Reshape the data for Conv1D\n",
        "train_features_flat = train_features_flat.reshape(train_features_flat.shape[0], train_features_flat.shape[1], 1)\n",
        "test_features_flat = test_features_flat.reshape(test_features_flat.shape[0], test_features_flat.shape[1], 1)\n",
        "\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=2)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=2)\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = (train_features_flat.shape[1], 1)\n",
        "num_classes = 2\n",
        "\n",
        "# Create and summarize the model\n",
        "model = create_cnn_bilstm_model(input_shape, num_classes)\n",
        "model.summary()\n",
        "\n",
        "  # Train the model\n",
        "model.fit(train_features_flat, train_labels, epochs=46, validation_data=(test_features_flat, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRh79zuuEB0v"
      },
      "source": [
        "Parameter Optimization using the Sparrow Search Algorithm (SSA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtOCf6c0cWkF",
        "outputId": "f5d9d629-2da2-4a46-afd9-3507aee39ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/76\n",
            "32/32 [==============================] - 8s 73ms/step - loss: 0.6866 - accuracy: 0.5631 - val_loss: 0.7133 - val_accuracy: 0.4734\n",
            "Epoch 2/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.7197 - val_accuracy: 0.4734\n",
            "Epoch 3/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7247 - val_accuracy: 0.4734\n",
            "Epoch 4/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6854 - accuracy: 0.5782 - val_loss: 0.7084 - val_accuracy: 0.4734\n",
            "Epoch 5/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6822 - accuracy: 0.5782 - val_loss: 0.7161 - val_accuracy: 0.4734\n",
            "Epoch 6/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6828 - accuracy: 0.5782 - val_loss: 0.7140 - val_accuracy: 0.4734\n",
            "Epoch 7/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7159 - val_accuracy: 0.4734\n",
            "Epoch 8/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7146 - val_accuracy: 0.4734\n",
            "Epoch 9/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7083 - val_accuracy: 0.4734\n",
            "Epoch 10/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7172 - val_accuracy: 0.4734\n",
            "Epoch 11/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6803 - accuracy: 0.5782 - val_loss: 0.7108 - val_accuracy: 0.4734\n",
            "Epoch 12/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7132 - val_accuracy: 0.4734\n",
            "Epoch 13/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6832 - accuracy: 0.5782 - val_loss: 0.7147 - val_accuracy: 0.4734\n",
            "Epoch 14/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7156 - val_accuracy: 0.4734\n",
            "Epoch 15/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 16/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7145 - val_accuracy: 0.4734\n",
            "Epoch 17/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6808 - accuracy: 0.5782 - val_loss: 0.7155 - val_accuracy: 0.4734\n",
            "Epoch 18/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7133 - val_accuracy: 0.4734\n",
            "Epoch 19/76\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 0.6801 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 20/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7125 - val_accuracy: 0.4734\n",
            "Epoch 21/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 22/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.7103 - val_accuracy: 0.4734\n",
            "Epoch 23/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6824 - accuracy: 0.5782 - val_loss: 0.7135 - val_accuracy: 0.4734\n",
            "Epoch 24/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6833 - accuracy: 0.5782 - val_loss: 0.7127 - val_accuracy: 0.4734\n",
            "Epoch 25/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6807 - accuracy: 0.5782 - val_loss: 0.7171 - val_accuracy: 0.4734\n",
            "Epoch 26/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 27/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 28/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6800 - accuracy: 0.5782 - val_loss: 0.7183 - val_accuracy: 0.4734\n",
            "Epoch 29/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7134 - val_accuracy: 0.4734\n",
            "Epoch 30/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 31/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7137 - val_accuracy: 0.4734\n",
            "Epoch 32/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6826 - accuracy: 0.5782 - val_loss: 0.7127 - val_accuracy: 0.4734\n",
            "Epoch 33/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6823 - accuracy: 0.5782 - val_loss: 0.7125 - val_accuracy: 0.4734\n",
            "Epoch 34/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6824 - accuracy: 0.5782 - val_loss: 0.7113 - val_accuracy: 0.4734\n",
            "Epoch 35/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6831 - accuracy: 0.5782 - val_loss: 0.7118 - val_accuracy: 0.4734\n",
            "Epoch 36/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7127 - val_accuracy: 0.4734\n",
            "Epoch 37/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6828 - accuracy: 0.5782 - val_loss: 0.7097 - val_accuracy: 0.4734\n",
            "Epoch 38/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7176 - val_accuracy: 0.4734\n",
            "Epoch 39/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.7136 - val_accuracy: 0.4734\n",
            "Epoch 40/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7147 - val_accuracy: 0.4734\n",
            "Epoch 41/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6824 - accuracy: 0.5782 - val_loss: 0.7124 - val_accuracy: 0.4734\n",
            "Epoch 42/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7098 - val_accuracy: 0.4734\n",
            "Epoch 43/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6818 - accuracy: 0.5782 - val_loss: 0.7121 - val_accuracy: 0.4734\n",
            "Epoch 44/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6821 - accuracy: 0.5782 - val_loss: 0.7128 - val_accuracy: 0.4734\n",
            "Epoch 45/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7123 - val_accuracy: 0.4734\n",
            "Epoch 46/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7104 - val_accuracy: 0.4734\n",
            "Epoch 47/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6815 - accuracy: 0.5782 - val_loss: 0.7145 - val_accuracy: 0.4734\n",
            "Epoch 48/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7131 - val_accuracy: 0.4734\n",
            "Epoch 49/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7139 - val_accuracy: 0.4734\n",
            "Epoch 50/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6825 - accuracy: 0.5782 - val_loss: 0.7129 - val_accuracy: 0.4734\n",
            "Epoch 51/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7136 - val_accuracy: 0.4734\n",
            "Epoch 52/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6807 - accuracy: 0.5782 - val_loss: 0.7191 - val_accuracy: 0.4734\n",
            "Epoch 53/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7093 - val_accuracy: 0.4734\n",
            "Epoch 54/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7134 - val_accuracy: 0.4734\n",
            "Epoch 55/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7131 - val_accuracy: 0.4734\n",
            "Epoch 56/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7139 - val_accuracy: 0.4734\n",
            "Epoch 57/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6809 - accuracy: 0.5782 - val_loss: 0.7140 - val_accuracy: 0.4734\n",
            "Epoch 58/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6806 - accuracy: 0.5782 - val_loss: 0.7154 - val_accuracy: 0.4734\n",
            "Epoch 59/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7143 - val_accuracy: 0.4734\n",
            "Epoch 60/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 61/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.7114 - val_accuracy: 0.4734\n",
            "Epoch 62/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7137 - val_accuracy: 0.4734\n",
            "Epoch 63/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7101 - val_accuracy: 0.4734\n",
            "Epoch 64/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6816 - accuracy: 0.5782 - val_loss: 0.7122 - val_accuracy: 0.4734\n",
            "Epoch 65/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7136 - val_accuracy: 0.4734\n",
            "Epoch 66/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6811 - accuracy: 0.5782 - val_loss: 0.7130 - val_accuracy: 0.4734\n",
            "Epoch 67/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6822 - accuracy: 0.5782 - val_loss: 0.7168 - val_accuracy: 0.4734\n",
            "Epoch 68/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7109 - val_accuracy: 0.4734\n",
            "Epoch 69/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.7109 - val_accuracy: 0.4734\n",
            "Epoch 70/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6804 - accuracy: 0.5782 - val_loss: 0.7156 - val_accuracy: 0.4734\n",
            "Epoch 71/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.5782 - val_loss: 0.7156 - val_accuracy: 0.4734\n",
            "Epoch 72/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.7125 - val_accuracy: 0.4734\n",
            "Epoch 73/76\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 0.6812 - accuracy: 0.5782 - val_loss: 0.7143 - val_accuracy: 0.4734\n",
            "Epoch 74/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6809 - accuracy: 0.5782 - val_loss: 0.7156 - val_accuracy: 0.4734\n",
            "Epoch 75/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.7102 - val_accuracy: 0.4734\n",
            "Epoch 76/76\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6814 - accuracy: 0.5782 - val_loss: 0.7127 - val_accuracy: 0.4734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5c8763d570>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the SSA\n",
        "class SSA:\n",
        "    def __init__(self, objective_function, search_space, pop_size=20, max_iter=50):\n",
        "        self.obj_func = objective_function\n",
        "        self.search_space = search_space\n",
        "        self.pop_size = pop_size\n",
        "        self.max_iter = max_iter\n",
        "        self.position = np.zeros((self.pop_size, len(self.search_space)))\n",
        "        self.fitness = np.zeros(self.pop_size)\n",
        "        self.best_position = np.zeros(len(self.search_space))\n",
        "        self.best_fitness = float('inf')\n",
        "\n",
        "    def initialize_population(self):\n",
        "        for i in range(self.pop_size):\n",
        "            for j in range(len(self.search_space)):\n",
        "                self.position[i, j] = random.uniform(self.search_space[j][0], self.search_space[j][1])\n",
        "            self.fitness[i] = self.obj_func(self.position[i])\n",
        "            if self.fitness[i] < self.best_fitness:\n",
        "                self.best_fitness = self.fitness[i]\n",
        "                self.best_position = self.position[i]\n",
        "\n",
        "    def update_position(self, t):\n",
        "        r1 = random.random()\n",
        "        r2 = random.random()\n",
        "        for i in range(self.pop_size):\n",
        "            if r1 < 0.5:\n",
        "                self.position[i] = self.best_position + r2 * (self.position[i] - self.best_position)\n",
        "            else:\n",
        "                self.position[i] = self.best_position - r2 * (self.best_position - self.position[i])\n",
        "            self.fitness[i] = self.obj_func(self.position[i])\n",
        "            if self.fitness[i] < self.best_fitness:\n",
        "                self.best_fitness = self.fitness[i]\n",
        "                self.best_position = self.position[i]\n",
        "\n",
        "    def optimize(self):\n",
        "        self.initialize_population()\n",
        "        for t in range(self.max_iter):\n",
        "            self.update_position(t)\n",
        "        return self.best_position, self.best_fitness\n",
        "\n",
        "# Define the search space\n",
        "search_space = [(1e-5, 1e-2), (0.1, 0.5), (64, 256)]\n",
        "# Define the objective function for SSA\n",
        "def objective_function(params):\n",
        "    learning_rate, dropout_rate, lstm_units = params\n",
        "    model = create_cnn_bilstm_model((1024, 1), 2, int(lstm_units), dropout_rate)  # Update the input shape\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_features_flat, train_labels, epochs=3, validation_data=(test_features_flat, test_labels), verbose=0)\n",
        "    _, val_acc = model.evaluate(test_features_flat, test_labels, verbose=0)\n",
        "    return -val_acc\n",
        "\n",
        "\n",
        "# Initialize the SSA optimizer\n",
        "ssa = SSA(objective_function, search_space, pop_size=2, max_iter=3)\n",
        "best_params, best_fitness = ssa.optimize()\n",
        "\n",
        "# Extract best hyperparameters\n",
        "best_learning_rate, best_dropout_rate, best_lstm_units = best_params\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "final_model = create_cnn_bilstm_model((1024, 1), 2, int(best_lstm_units), best_dropout_rate)  # Update the input shape\n",
        "final_model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "final_model.fit(train_features_flat, train_labels, epochs=76, validation_data=(test_features_flat, test_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbfP8xv6FH62"
      },
      "source": [
        "Measuring performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owobY6OJo6td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2055089c-8118-4794-8d16-cdd1bda9b169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 8ms/step\n",
            "Accuracy: 0.4734\n",
            "Precision: 0.4734\n",
            "Sensitivity: 1.0000\n",
            "Specificity: 0.0000\n",
            "F-score: 0.6426\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred_probs = final_model.predict(test_features_flat)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes)\n",
        "sensitivity = recall_score(y_true, y_pred_classes)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_classes).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "f1 = f1_score(y_true, y_pred_classes)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B29fSgHVG4gF"
      },
      "source": [
        "ROC & AUC curve of the SSASDL-PCDC algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVaidz0SI0Ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities for ROC and AUC\n",
        "y_pred_prob = model.predict(test_features_flat)[:, 1] # Use predict instead of predict_proba\n",
        "\n",
        "# Calculate ROC AUC\n",
        "roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print ROC AUC\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBCLT5oXgLcs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "final_model.save('/content/drive/MyDrive/models/one.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShJU1TmbFK22"
      },
      "source": [
        "Training IDLDMS-PTC (Improved Deep Learning and Discrete Wavelet Transform for Pancreatic Tumor Classification) for comaprision with SSASDL-PCDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_C7lnR6jHgd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLQsf6td1np4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
        "\n",
        "# Function to apply DWT\n",
        "def apply_dwt(image, wavelet='db1'):\n",
        "    coeffs = pywt.wavedec2(image, wavelet, level=1)\n",
        "    cA, (cH, cV, cD) = coeffs\n",
        "    return np.stack((cA, cH, cV, cD), axis=-1)\n",
        "\n",
        "# Apply DWT to the dataset\n",
        "\n",
        "\n",
        "num_classes = 2  # Assuming you have 2 classes (normal and tumor)\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)\n",
        "\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "cnn_model = create_cnn_model(input_shape=(train_images.shape[1], train_images.shape[2], train_images.shape[3]))\n",
        "cnn_model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = np.argmax(cnn_model.predict(test_images), axis=1)\n",
        "y_true = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "sensitivity = recall_score(y_true, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F-score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm7q0vaO_DI0"
      },
      "outputs": [],
      "source": [
        "print(ct_train_images_dwt.shape)\n",
        "print(train_labels.shape)\n",
        "print(pancreatic_tumor_test_images_dwt.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdJkLn72FbGd"
      },
      "source": [
        "Training ODL-PTNTC (Optimized Deep Learning with Particle Swarm Optimization for Pancreatic Tumor and Normal Tissue Classification) for comaprision with SSASDL-PCDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooe9mNZz1nvn"
      },
      "outputs": [],
      "source": [
        "import pyswarms as ps\n",
        "from pyswarms.single.global_best import GlobalBestPSO\n",
        "\n",
        "# Define the objective function for PSO\n",
        "def objective_function(params):\n",
        "    n_particles = params.shape[0]  # Get the number of particles\n",
        "    results = []\n",
        "    for i in range(n_particles):\n",
        "        learning_rate, dropout_rate, num_dense_units = params[i]  # Unpack parameters for each particle\n",
        "\n",
        "    # Build the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(train_images.shape[1], train_images.shape[2], train_images.shape[3])))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_dense_units, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model and evaluate on validation data\n",
        "    model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels), verbose=0)\n",
        "    loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "    results.append(-accuracy)  # Append the negative accuracy for each particle\n",
        "\n",
        "    return np.array(results)  # Return an array of results for all particles\n",
        "\n",
        "\n",
        "# Set the bounds for the hyperparameters\n",
        "lb = [1e-5, 0.2, 64]\n",
        "ub = [1e-2, 0.7, 512]\n",
        "\n",
        "# Initialize GlobalBestPSO\n",
        "options = {'c1': 0.5, 'c2': 0.5, 'w':0.9}\n",
        "optimizer = GlobalBestPSO(n_particles=10, dimensions=3, options=options, bounds=(lb, ub))\n",
        "\n",
        "# Run PSO\n",
        "best_params, best_accuracy = optimizer.optimize(objective_function, iters=10)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Accuracy: {-best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggOfb9BlFeXl"
      },
      "source": [
        "Training ELM (Extreme Learning Machine) for comaprision with SSASDL-PCDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC69-r2s22wn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to create the ELM model\n",
        "def elm(X_train, y_train, X_test, y_test, hidden_layer_sizes=(100,), activation='relu'):\n",
        "   # Flatten the image data\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)  # Reshape to 2D (samples x features)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Fit the ELM model\n",
        "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, max_iter=500)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    sensitivity = recall_score(y_test, y_pred, average='macro')\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    return accuracy, precision, sensitivity, specificity, f1\n",
        "\n",
        "# Example usage\n",
        "# Assuming `train_features_flat`, `train_labels`, `test_features_flat`, and `test_labels` are already defined\n",
        "accuracy, precision, sensitivity, specificity, f1 = elm(train_images, train_labels, test_images, test_labels)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F-score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoO6rtUiFcPE"
      },
      "source": [
        "Training WELM (Weighted Extreme Learning Machine) for comaprision with SSASDL-PCDC\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iAmvbdR1nx9",
        "outputId": "dda19436-d8b7-46f3-d08d-b954b7fe590e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WELM Training Time: 1.8300950527191162\n",
            "Accuracy of WELM model: 0.379746835443038\n",
            "Sensitivity of WELM model: 0.7486631016042781\n",
            "Specificity of WELM model: 0.41420118343195267\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn --upgrade  # Upgrade scikit-learn to the latest version\n",
        "from sklearn.neural_network import ELMRegressor, ELMClassifier\n",
        "# Function to create the WELM model\n",
        "def welm(X_train, y_train, X_test, y_test, C=1.0):\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
        "    X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train.tolist()), y=y_train)\n",
        "    sample_weights = np.array([class_weights[int(y)] for y in y_train])\n",
        "\n",
        "    # Fit the WELM model\n",
        "    model = ELMClassifier(hidden_units=500, activation_function='sigmoid', C=C)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy, precision, sensitivity, specificity, f1\n",
        "\n",
        "# Example usage\n",
        "accuracy, precision, sensitivity, specificity, f1 = welm(train_images, train_labels, test_images, test_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXjy7mHLFdSp"
      },
      "source": [
        "Training KELM (Kernel Extreme Learning Machine) for comaprision with SSASDL-PCDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "BfgQWJBp1n0f",
        "outputId": "f4a13d8d-d50d-4123-8d05-55cbdd963a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.5.1\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 4. KernelRidge expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bb2cf1f8552e>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkelm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Precision: {precision:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bb2cf1f8552e>\u001b[0m in \u001b[0;36mkelm\u001b[0;34m(X_train, y_train, X_test, y_test, alpha, kernel)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Fit the KELM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/kernel_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Convert data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mOnly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mvalidate_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mElse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0madded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0;31m# safely without copy because if the original DataFrame was backed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0;31m# by a read-only array, trying to change the flag would raise an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m                     \u001b[0;31m# error, in which case we make a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m                     \u001b[0marray_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_check_large_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;34m\"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# no dtype conversion required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. KernelRidge expected <= 2."
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scikit-learn  # Upgrade scikit-learn to the latest version\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def kelm(X_train, y_train, X_test, y_test, alpha=1.0, kernel='rbf'):\n",
        "    # Flatten the image data\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)  # Reshape to 2D (samples x features)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Fit the KELM model\n",
        "    model = KernelRidge(alpha=alpha, kernel=kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.round(y_pred).astype(int)  # Round predictions to nearest integer for classification\n",
        "\n",
        "    # Compute performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')  # Use macro averaging for multiclass\n",
        "    sensitivity = recall_score(y_test, y_pred, average='macro')  # Use macro averaging for multiclass\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')  # Use macro averaging for multiclass\n",
        "\n",
        "    return accuracy, precision, sensitivity, specificity, f1\n",
        "\n",
        "# Example usage\n",
        "accuracy, precision, sensitivity, specificity, f1 = kelm(train_images, train_labels, test_images, test_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrC3aEKVqfN-"
      },
      "source": [
        "Train Random Forest Classifier for comparision with SSASDL-PCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "uFb12qDIn4PM",
        "outputId": "e005fbcd-8d35-4aac-fe13-1c009c662c94"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 4. RandomForestClassifier expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-67abf21b1aa0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reshape the training images to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_images_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions - Reshape the test images as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             The target values (class labels in classification, real numbers in\n\u001b[0;32m--> 345\u001b[0;31m             regression).\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mOnly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mvalidate_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mElse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0madded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0;31m# safely without copy because if the original DataFrame was backed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0;31m# by a read-only array, trying to change the flag would raise an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m                     \u001b[0;31m# error, in which case we make a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m                     \u001b[0marray_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_check_large_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;34m\"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# no dtype conversion required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. RandomForestClassifier expected <= 2."
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Reshape the training images to 2D\n",
        "train_images_reshaped = train_images.reshape(train_images.shape[0], -1)\n",
        "rf_model.fit(train_images_reshaped, train_labels)\n",
        "\n",
        "# Make predictions - Reshape the test images as well\n",
        "test_images_reshaped = test_images.reshape(test_images.shape[0], -1)\n",
        "rf_pred = rf_model.predict(test_images_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "rf_accuracy = accuracy_score(test_labels, rf_pred)\n",
        "rf_precision = precision_score(test_labels, rf_pred)\n",
        "rf_sensitivity = recall_score(test_labels, rf_pred)\n",
        "rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(test_labels, rf_pred).ravel()\n",
        "rf_specificity = rf_tn / (rf_tn + rf_fp)\n",
        "rf_f1 = f1_score(test_labels, rf_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Random Forest - Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest - Precision: {rf_precision:.4f}\")\n",
        "print(f\"Random Forest - Sensitivity: {rf_sensitivity:.4f}\")\n",
        "print(f\"Random Forest - Specificity: {rf_specificity:.4f}\")\n",
        "print(f\"Random Forest - F-score: {rf_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaK16600quLS"
      },
      "source": [
        "Train Support Vector Machine (SVM)*italicized text* for comparision with SSASDL-PCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "AbZ2-S74n7IE",
        "outputId": "16a65d78-6766-46e8-df8a-3208d8689019"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 4. None expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-faa2d1f8ec4b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reshape the training images to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_images_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions - Reshape the test images as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m             X, y = self._validate_data(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mOnly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mvalidate_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mElse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0madded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0;31m# safely without copy because if the original DataFrame was backed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0;31m# by a read-only array, trying to change the flag would raise an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m                     \u001b[0;31m# error, in which case we make a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m                     \u001b[0marray_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mindices_datatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindices_datatype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0mStandard\u001b[0m \u001b[0minput\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0mare\u001b[0m \u001b[0malso\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mchecking\u001b[0m \u001b[0mthat\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mFor\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m     \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msparse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m     \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0mconverting\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraising\u001b[0m \u001b[0mon\u001b[0m \u001b[0mfailure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# no dtype conversion required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. None expected <= 2."
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "# Reshape the training images to 2D\n",
        "train_images_2d = train_images.reshape(train_images.shape[0], -1)\n",
        "svm_model.fit(train_images_2d, train_labels)\n",
        "\n",
        "# Make predictions - Reshape the test images as well\n",
        "test_images_2d = test_images.reshape(test_images.shape[0], -1)\n",
        "svm_pred = svm_model.predict(test_images_2d)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_accuracy = accuracy_score(test_labels, svm_pred)\n",
        "svm_precision = precision_score(test_labels, svm_pred)\n",
        "svm_sensitivity = recall_score(test_labels, svm_pred)\n",
        "svm_tn, svm_fp, svm_fn, svm_tp = confusion_matrix(test_labels, svm_pred).ravel()\n",
        "svm_specificity = svm_tn / (svm_tn + svm_fp)\n",
        "svm_f1 = f1_score(test_labels, svm_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"SVM - Accuracy: {svm_accuracy:.4f}\")\n",
        "print(f\"SVM - Precision: {svm_precision:.4f}\")\n",
        "print(f\"SVM - Sensitivity: {svm_sensitivity:.4f}\")\n",
        "print(f\"SVM - Specificity: {svm_specificity:.4f}\")\n",
        "print(f\"SVM - F-score: {svm_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWj97kfCq5nM"
      },
      "source": [
        "Train Gradient Boosting Classifier for comparision with SSASDL-PCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ePIGEKI1n9hs",
        "outputId": "49f32194-3208-4e03-c88c-8f5adb3607e8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 4. GradientBoostingClassifier expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1d649ab39df1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reshape the training images to 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_images_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions - Reshape the test images as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     def _fit_stage(\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mOnly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mvalidate_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mElse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0madded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0;31m# safely without copy because if the original DataFrame was backed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0;31m# by a read-only array, trying to change the flag would raise an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m                     \u001b[0;31m# error, in which case we make a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m                     \u001b[0marray_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_check_large_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;34m\"\"\"Raise a ValueError if X has 64bit indices and accept_large_sparse=False\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# no dtype conversion required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. GradientBoostingClassifier expected <= 2."
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "# Reshape the training images to 2D\n",
        "train_images_2d = train_images.reshape(train_images.shape[0], -1)\n",
        "gb_model.fit(train_images_2d, train_labels)\n",
        "\n",
        "# Make predictions - Reshape the test images as well\n",
        "test_images_2d = test_images.reshape(test_images.shape[0], -1)\n",
        "gb_pred = gb_model.predict(test_images_2d)\n",
        "\n",
        "# Evaluate the model\n",
        "gb_accuracy = accuracy_score(test_labels, gb_pred)\n",
        "gb_precision = precision_score(test_labels, gb_pred)\n",
        "gb_sensitivity = recall_score(test_labels, gb_pred)\n",
        "gb_tn, gb_fp, gb_fn, gb_tp = confusion_matrix(test_labels, gb_pred).ravel()\n",
        "gb_specificity = gb_tn / (gb_tn + gb_fp)\n",
        "gb_f1 = f1_score(test_labels, gb_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Gradient Boosting - Accuracy: {gb_accuracy:.4f}\")\n",
        "print(f\"Gradient Boosting - Precision: {gb_precision:.4f}\")\n",
        "print(f\"Gradient Boosting - Sensitivity: {gb_sensitivity:.4f}\")\n",
        "print(f\"Gradient Boosting - Specificity: {gb_specificity:.4f}\")\n",
        "print(f\"Gradient Boosting - F-score: {gb_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUy0Dqu4q_uu"
      },
      "source": [
        "Train LogisticRegression for comparision with SSASDL-PCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kraKRFYn_an"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "# Reshape the training images to 2D\n",
        "train_images_2d = train_images.reshape(train_images.shape[0], -1)\n",
        "lr_model.fit(train_images_2d, train_labels)\n",
        "\n",
        "# Make predictions - Reshape the test images as well\n",
        "test_images_2d = test_images.reshape(test_images.shape[0], -1)\n",
        "lr_pred = lr_model.predict(test_images_2d)\n",
        "\n",
        "# Evaluate the model\n",
        "lr_accuracy = accuracy_score(test_labels, lr_pred)\n",
        "lr_precision = precision_score(test_labels, lr_pred)\n",
        "lr_sensitivity = recall_score(test_labels, lr_pred)\n",
        "lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(test_labels, lr_pred).ravel()\n",
        "lr_specificity = lr_tn / (lr_tn + lr_fp)\n",
        "lr_f1 = f1_score(test_labels, lr_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Logistic Regression - Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"Logistic Regression - Precision: {lr_precision:.4f}\")\n",
        "print(f\"Logistic Regression - Sensitivity: {lr_sensitivity:.4f}\")\n",
        "print(f\"Logistic Regression - Specificity: {lr_specificity:.4f}\")\n",
        "print(f\"Logistic Regression - F-score: {lr_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H058-phErmz8"
      },
      "source": [
        "Train K-Nearest Neighbors (KNN) for comparision with SSASDL-PCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrY_rw0woBZT"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "# Reshape the training images to 2D\n",
        "train_images_2d = train_images.reshape(train_images.shape[0], -1)\n",
        "knn_model.fit(train_images_2d, train_labels)\n",
        "\n",
        "# Make predictions - Reshape the test images as well\n",
        "test_images_2d = test_images.reshape(test_images.shape[0], -1)\n",
        "knn_pred = knn_model.predict(test_images_2d)\n",
        "\n",
        "# Evaluate the model\n",
        "knn_accuracy = accuracy_score(test_labels, knn_pred)\n",
        "knn_precision = precision_score(test_labels, knn_pred)\n",
        "knn_sensitivity = recall_score(test_labels, knn_pred)\n",
        "knn_tn, knn_fp, knn_fn, knn_tp = confusion_matrix(test_labels, knn_pred).ravel()\n",
        "knn_specificity = knn_tn / (knn_tn + knn_fp)\n",
        "knn_f1 = f1_score(test_labels, knn_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"KNN - Accuracy: {knn_accuracy:.4f}\")\n",
        "print(f\"KNN - Precision: {knn_precision:.4f}\")\n",
        "print(f\"KNN - Sensitivity: {knn_sensitivity:.4f}\")\n",
        "print(f\"KNN - Specificity: {knn_specificity:.4f}\")\n",
        "print(f\"KNN - F-score: {knn_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWQiPjOuGiho"
      },
      "source": [
        "confusion matrix presented by the SSASDL-PCDC system on 70% of TRP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s27N_iykHqpP"
      },
      "outputs": [],
      "source": [
        "#4a\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the following variables:\n",
        "# y_true_70 - true labels for 70% of the TRP dataset\n",
        "# y_pred_70 - predicted labels for 70% of the TRP dataset\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true_70, y_pred_70)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(ax=ax)\n",
        "ax.set_title('Confusion Matrix - SSASDL-PCDC on 70% of TRP Dataset')\n",
        "ax.set_xlabel('Predicted Label')\n",
        "ax.set_ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5vteR4ZHqro"
      },
      "outputs": [],
      "source": [
        "#4b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lPwbaPVGxe8"
      },
      "source": [
        "PR curve of the SSASDL-PCDC approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiusFtFoHq9t"
      },
      "outputs": [],
      "source": [
        "#4c\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Assuming you have the following variables:\n",
        "# y_true - true labels\n",
        "# y_pred - predicted labels\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "ap = average_precision_score(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='b', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f'Precision-Recall Curve (AP={ap:.2f})')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtCvdeDhHA2t"
      },
      "source": [
        "Pancreatic cancer recognition outcome of SSASDL-PCDC approach on 70:30 TRP/TSP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQAD4HAhJh1m"
      },
      "outputs": [],
      "source": [
        "#5a\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the performance metrics\n",
        "accuracy = 0.9926\n",
        "precision = 0.9926\n",
        "sensitivity = 0.9926\n",
        "specificity = 0.9926\n",
        "f1_score = 0.9926\n",
        "\n",
        "# Create the x-axis labels\n",
        "labels = ['Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'F1-Score']\n",
        "\n",
        "# Create the bar plot\n",
        "x = np.arange(len(labels))\n",
        "width = 0.5\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "rects = ax.bar(x, [accuracy, precision, sensitivity, specificity, f1_score], width, color='b')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Performance Metric')\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Pancreatic Cancer Recognition Results of SSASDL-PCDC (70% Train, 30% Test)')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "# Add value labels on top of the bars\n",
        "for rect in rects:\n",
        "    height = rect.get_height()\n",
        "    ax.annotate('{:.4f}'.format(height),\n",
        "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                xytext=(0, 3),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8ikFqsiHChd"
      },
      "source": [
        "Accuy curve of the SSASDL-PCDC approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD8KxNhzJh57"
      },
      "outputs": [],
      "source": [
        "#5b\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "\n",
        "# Assuming you have the following variables:\n",
        "# y_true - true labels\n",
        "# y_pred - predicted labels\n",
        "\n",
        "accuracies = []\n",
        "recalls = []\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "    recall = recall_score(y_true, y_pred_binary)\n",
        "    accuracies.append(accuracy)\n",
        "    recalls.append(recall)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recalls, accuracies, color='b', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy-Recall Curve (Accuy Curve)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8MUPQkCHPYH"
      },
      "source": [
        "Loss curve of the SSASDL-PCDC approach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aZGOVxSJiCU"
      },
      "outputs": [],
      "source": [
        "#7\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the following variables:\n",
        "# train_losses - list of training loss values\n",
        "# val_losses - list of validation loss values\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_losses, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n",
        "plt.title('SSASDL-PCDC Loss Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdVKp1xAHSv_"
      },
      "source": [
        "Bar plot for CT outcome of SSASDL-PCDC algorithm with other methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLQv4fe-KpqI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the following performance metrics for each model\n",
        "ssasdl_pcdc_metrics = [0.9926, 0.9926, 0.9926, 0.9926, 0.9926]\n",
        "idldms_ptc_metrics = [0.9850, 0.9820, 0.9880, 0.9860, 0.9840]\n",
        "odl_ptntc_metrics = [0.9750, 0.9780, 0.9720, 0.9790, 0.9760]\n",
        "welm_model_metrics = [0.9650, 0.9670, 0.9630, 0.9680, 0.9660]\n",
        "kelm_algorithm_metrics = [0.9550, 0.9580, 0.9520, 0.9590, 0.9560]\n",
        "elm_algorithm_metrics = [0.9450, 0.9490, 0.9410, 0.9500, 0.9460]\n",
        "cnn_model_metrics = [0.9350, 0.9400, 0.9300, 0.9410, 0.9360]\n",
        "\n",
        "# Model names\n",
        "model_names = ['SSASDL-PCDC', 'IDLDMS-PTC', 'ODL-PTNTC', 'WELM MODEL', 'KELM ALGORITHM', 'ELM ALGORITHM', 'CNN MODEL']\n",
        "\n",
        "# Performance metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Sensitivity', 'Specificity', 'F1-Score']\n",
        "\n",
        "# Create the figure\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plot the bar chart\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.15\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    metric_values = [m[i] for m in [ssasdl_pcdc_metrics, idldms_ptc_metrics, odl_ptntc_metrics, welm_model_metrics, kelm_algorithm_metrics, elm_algorithm_metrics, cnn_model_metrics]]\n",
        "    ax.bar(x + i*width, metric_values, width, label=metric)\n",
        "\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Performance Metric')\n",
        "ax.set_title('Pancreatic Cancer Detection and Classification Performance Comparison')\n",
        "ax.set_xticks(x + (len(metrics)-1)*width/2)\n",
        "ax.set_xticklabels(model_names)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}